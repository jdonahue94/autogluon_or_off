# Import necessary libraries
import pandas as pd
import numpy as np
from xgboost import XGBClassifier
from autogluon.tabular import TabularPredictor
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Load the dataset
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
columns = [
    "age", "workclass", "fnlwgt", "education", "education-num",
    "marital-status", "occupation", "relationship", "race", "sex",
    "capital-gain", "capital-loss", "hours-per-week", "native-country", "income"
]
data = pd.read_csv(url, names=columns, header=None, na_values="?", skipinitialspace=True)

# Preprocess the dataset
data.dropna(inplace=True)
data['income'] = data['income'].apply(lambda x: 1 if x.strip() == ">50K" else 0)
categorical_features = data.select_dtypes(include=['object']).columns.tolist()
for col in categorical_features:
    data[col] = data[col].astype('category')

# Split the data into train and test sets
X = data.drop('income', axis=1)
y = data['income']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train XGBoost model
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')
xgb_model.fit(X_train, y_train)
xgb_predictions = xgb_model.predict(X_test)
xgb_accuracy = accuracy_score(y_test, xgb_predictions)
print(f"XGBoost Model Accuracy: {xgb_accuracy:.2f}")

# Train AutoGluon model
ag_model = TabularPredictor(label='income').fit(train_data=TabularPredictor.DataFrame(X_train.join(y_train)),
                                                presets='medium_quality_faster_train')
ag_predictions = ag_model.predict(X_test)
ag_accuracy = accuracy_score(y_test, ag_predictions)
print(f"AutoGluon Model Accuracy: {ag_accuracy:.2f}")

# Compare performances
print("Performance Comparison:")
print(f"XGBoost Accuracy: {xgb_accuracy:.4f}")
print(f"AutoGluon Accuracy: {ag_accuracy:.4f}")
